#7 ways to make a good mental health app#
 1.	Clearly define and engage with your intended audience2.	Be Interactive, move beyond text and make the app part of something bigger3.	Be credible4.	Never underestimate the impact of stigma5.	Be clear of security risks6.	Risks might not be what you think7.	Be progressive
Have you ever thought of creating a mental health app? The role of mobile phone apps in mental health treatment is a relatively new treatment tool. Apps can be utilised by mental health practitioners, individuals interested in mental well being, those being treated from an addiction as well as those with chronic debilitating psychiatric conditions. [Various studies] (http://mental.jmir.org/2014/1/e5/)suggest that people with mental health conditions are interested in using apps in their treatment increasing the likelihood of adoption. 
But what makes a good mental health app and how can you ensure you are making a good one? In this article I’ll walk through some of the particulars of the mental health sector, explore some interesting apps and innovations and discuss the challenges for you as a developer. 
##1.	You need to clearly define and engage with your intended audience##
Before you get too excited about creating the technical abilities of your app, take a step back and consider whom your audience is. This will help you determine the functionalities required from your app.  A mental health consumer with schizophrenia wanting to reduce their hallucinations would for example, have different needs to someone seeking meditation and positive affirmations (with an emphasis on wellbeing) or a mental health professional. But once you’ve delineated between health professional and health consumer don’t assume either cohort to be a homogenous entity. 
A ‘depression’ app for example might;
*     Educate and inform people who think they may have depression (with the end result being contact with a medical professional)*     Assist the friends or family of someone with depression*	Be part of a diagnostic tool in conjunction with a mental health professional *	Be part of a treatment tool (for example integrating therapeutic strategies and a mood journal)*	Be an early predictor of relapses into depression for someone who is already receiving treatment or has received treatment in the past*	Provide online talk therapy as an alternative to face to face counselling
These are all very different and require a different focus! 
Further, the experiences of different health consumers vary greatly depending on a range of factors including age, symptoms and diagnosis.   The creators of [Mindshift] (http://www.anxietybc.com/mobile-app), an app for young people in British Columbia experiencing anxiety, found that young people wanted an downloadable app to save on data plans, which contained a minimum of text and was discrete in design and icon to avoid disclosing their usage to inquisitive peers. This differs to the experiences of older people with dementia for example, who may require an app with larger test, reminders and tracking of the location of their mobile phone. It has been found that people with schizophrenia can experience short-term memory loss, so  apps that display a question on one page and response options on the next can be ineffectual and require an app that does not change screens or require scrolling. Short-term memory loss is a symptom of schizophrenia, [so even apps that display a question on one page and response options on the next could pose added challenges] (http://thedartmouth.com/2013/11/06/focus-app-helps-mentally-ill-patients/ ). To remedy this, Ben-Zeev created the app so that it does not change screens or require scrolling, and people can only move forward through prompts, reducing as many options for confusion as possible.If you’re thinking, well, how do I find this out? The most obvious way is to ask and learn. Don’t just read a few articles on the Internet go to where to people who will use your app are. In creating [Mindshift](http://www.anxietybc.com/mobile-app) for example, [B’stro] (http://bstro.com/) held focus groups to find out what young people experiencing anxiety needed in an app. 
This research should include plenty of interaction with not only the mental health consumers but also the health care industry.  The addiction sector for example, has had some access in alcohol recovery through creating customisable apps for their patients, which include localised information and personalised support. A great demonstration of this is [A-Chess] (http://chess.wisc.edu/chess/projects/AddictionChess.aspx), a relapse prevention multi purpose app that works in addiction recovery. Its success is in its detail; it can be tailored by the health professional to identify specific needs and triggers of the client. 

Insert video from here https://www.youtube.com/watch?v=c3NYShJNg24
Whilst the video is a little naff, it’s worth a quick look to see the app in action, especially the integration of pre-determined trigger times and locations, an assessment of mood, an offer of subsequent coping strategies, an offer of a video call with on-call counsellor questions, a video played when the user rejects then phone call then a subsequent phone call. Essentially, to create a meaningful app, it’s vital to engage with specialist clinicians in your health subject areas and also the people who will be your end users.  Partnering with a University research department, engaging with the national mental health associations, contacting mental health consumer advocates, running focus groups and researching what others are doing and how it is working are all credible ways to do this. ##Be Interactive, move beyond text and make the app part of something bigger##A text-based app can be a useful tool particularly for those seeking educational resources over treatment.  But it’s not terribly exciting if it does less than a desk top based program, especially when the portability, discretion and immediacy of a app has so many advantages. 
Tactility is one example where an app can come into its own. [Let Panic Go] is designed for people who experience panic attacks. When people feel a panic attack coming on, they can launch Let Panic Go and tap the screen in sync with each breath to determine how fast they're breathing. For some people, this repetitive action is enough to slow down their rate of breathing. But if it's not, the app will suggest a slower pace that the user can try to match. Once breathing is under control, the app offers other assistance to help the user through the attack.
Tracking is another example. In the A-Chess program, app users are able to enter a map of places associated with previous drug use and the phone activates a series of interactions when they travel near these places. A number of mental health apps also incorporate counselling sessions with professionals. The delivery of these varies and can include [private chat rooms] (https://play.google.com/store/apps/details?id=com.betterhelp) and [face to face therapy] (https://play.google.com/store/apps/details?id=com.talkspace.talkspaceapp) Others offer a [peer network] (https://play.google.com/store/apps/details?id=com.bearpty.talklife) for support including private messages, [online meetings](https://play.google.com/store/apps/details?id=com.blazingraptor.recovery) and discussion groups.Many of you gamers may already espouse the virtues of gaming as a mental health tool. [Super Better](https://play.google.com/store/apps/details?id=com.blazingraptor.recovery) is app-based game that helps the user build social, mental, and emotional resilience in the face of any illness, injury, or health goal. The user is required to complete a number of daily tasks or games to build their esteem and emotional well-being. Don’t forget the use of monitoring sensors in apps either, they are heavily influencing research in the treatment of mental health conditions, particularly for those with serious conditions that require constant monitoring of the symptoms and treatment to avoid relapse. An interesting example of this is [FOCUS](http://thedartmouth.com/2013/11/06/focus-app-helps-mentally-ill-patients/) , which is currently being developed at Dartmouth University as a schizophrenia management tool. This app uses techniques such as sleep modelling and predictive sensory data in relapse prediction by measuring the device lock time, ambient lighting and ambient audio to predict sleep time. Sensors can also measure changes in sleep patterns and increased isolation. This can be used to create a "lapse signature" unique to the patient, helping with clinical treatment and intervention. In turn [MOBILYZE](http://www.imedicalapps.com/2012/05/mobilyze-therapist-pocket/2/) utilises phone sensor values such as global positioning system, ambient light, recent calls to measure the users mood and monitor their wellbeing providing positive reinforcement for engagement in positive activities. 

By comparison [PRIORI](http://www.eecs.umich.edu/eecs/about/articles/2014/app_for_mood_swings.html) measures variances in a user’s speech pattern to predict manic and depressive states for people with bipolar.
And if you are using text-based resources, make them useful. A sleep or mood journal that can be air print enabled or readable by the mental health professional in real time (who may in reality only see a patient once a month) is far more meaningful than a list of positive affirmations. ##Be credible.##It’s difficult to define credibility. Whilst it would be ideal if all mental health apps were designed in collaboration with mental health professionals and launched after research based trials of their efficacy, the reality is that if this was to happen, the apps would be far behind the technology and researchers are struggling to determine a definitive guide to best practice mental health apps.
For example, a [study released this year] (http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4376135/#ref68) analyzing 243 depression apps available during 2013 revealed that many apps fail to incorporate evidence-based practices, health behavior theory, or clinical expertise into the design of the app.  The study excluded almost this many again for the lack of reporting of organizational affiliation and content source. It’s worth noting that the researchers failed to download or test any of the apps they were researching, claiming this mirrored the actual user experience when making the decision to download apps.[Other research] (http://www.psychology.org.au/Content.aspx?ID=5850)highlights the problem of clinical assessment of apps due to search terms/procedures used, the retail stores/research databases searched and the criteria used to determine app quality In the UK the National Health Service (NHS) is hoping to introduce a new [Kitemark] (http://www.sitepoint.com/doctor-can-prescribe-app/)for apps scheme, where apps will be accredited with the NHS logo and in the US this is taken a step further with  [iPrescribeApps](http://iprescribeapps.com/), a platform to enable physicians to access apps curated using evidence based criteria and expert opinion by the physicians of iMedicalApps. Individual apps could certainly be more transparent. I really like the way [Super Better‘s](https://itunes.apple.com/us/app/superbetter/id536634968?mt=8) incorporates science into their game style app. As a user plays, they find science icons hidden throughout missions. Clicking these icons gives access to the science of Super Better—including links to the research articles that everything's based on. ##Never underestimate the impact of stigma##Despite progress, people with mental health conditions still face stigma by peers, health professionals, insurance companies and potential employers.  Consider ways that your app can be used discretely in a public place with an option to use it without sound. The branding of the app should clear enough to clarify the purposes of the logo for someone in need but not discernable to others who may come across the users phone unlocked.  This may be one time when you need to be conservative with the bells and whistles. Perhaps one of the most ‘how could they?’ examples was Samaritans Radar, an app launched by mental health UK charity The Samaritans in 2014.  Radar was a free web application that used a specially designed algorithm that looked for specific keywords and phrases within a Tweet that could be connected to suicidal ideation. Once users signed up, they received an alert when one of the people they followed tweeted out certain trigger word. This happened without the knowledge or consent of the people who had made the original tweet. It was cited by some as ‘[a gift to bullies and trolls]’(http://digiday.com/brands/samaritans-radar-says-ad-business/). Experts further expressed concern about allowing the untrained public to monitor social media accounts using algorithms that may or may not be validated, potentially unwittingly and inaccurately labelling millions of people with mental health disorders. Because it worked using Oauth to operate as the application user, rather than a generic "@samaritans" user, it was able to access protected accounts. Before the app was pulled, [more than 3,000 people have activated Samaritans Radar, and over 1.64 million Twitter accounts were tracked] (http://www.bbc.co.uk/news/blogs-trending-29881099). ##Be clear of Security Risks## Clearly, mental health is an area where privacy and confidentiality are paramount. If a mobile app is used incorrectly (or an insecure app), user information could risk exposure. A user in particular needs to have clear and accurate information about whom the information they submit is shared with.  It may be shared with their primary mental health professional but is their medical journal shared with a pharmaceutical company? What about their health insurer? Are there future consequences? I can imagine a scenario for example, where an individual puts in a claim for depression in their workplace and the workplace insurer is able to demonstrate that they downloaded the app. Not as unlikely as it sounds given the [incidences of workplaces monitoring social media whilst employees are on sick leave](http://psychcentral.com/blog/archives/2009/11/20/woman-loses-sick-leave-benefits-for-depression-thanks-to-facebook-pics/). Privacy and confidentiality laws differ according to countries and states so be aware of what is required with the location you are working with. 
It has been suggested that a lack of connectively with apps makes preserving security difficult. One example to resolve this is to use standards-based coding and terms in your app - such as [DICOM, HL7, SNOMED and ICD-10](http://www.mhealthnews.com/news/10-steps-creating-safe-secure-healthcare-app?page=0) to increase the safety of shared information.  An understanding of inscription is also imperative, for example, when data enters the app, is stored in the app, and/or is sent from the app.##Risks might not be what you think##Perhaps the biggest risk to progress is that of time and effort. Mental health professionals currently have no real incentive or reimbursement encouraging patients to use mental health apps unless they are part of a funded research project. Also, I can’t help wondering about how much extra time is required for reading mood journals and sleep diaries. One risk is that [without ideal sensitivity and specificity] (http://www.psychiatrictimes.com/cultural-psychiatry/harnessing-social-media-and-mobile-apps-mental-health/page/0/2), the algorhythms for the notifying of mental health professionals could result in a number of false-positive notifications, ultimately leading to increased workload and costs. Health professionals are busy. I’m sure I’m not the only person who has gone to the doctor and had a busy professional use Google search rather than a medical resource.  Further, health apps prescribed by doctors may be classified as [health devices] (https://alexwyke.files.wordpress.com/2014/05/master-a4-white-paper-pdf.pdf)and hence in need of regulatory compliance. This could take a long time. (Interestingly one suggestion to avoid this is the use of QR codes). Further the costs of regulation could be a disincentive for developers-and consumers who would presumably bear the cost.##Be progressive##Mental health apps need to maintain their relevance whilst they are available. Medicine progresses (although perhaps not as quickly in mental health) as other areas with more funding. In building a mental health app you need to consider its progress throughout the span of its efficacy and the use by the user. What trajectory does the app have and is it customisable?  How does it remain relevant when a user becomes well? How does is maintain good mental health after periods of progress by the user? I’m not sure there has been any research into the longer-term efficacy of mental health apps on the commercial market; it would definitely be interesting for developers to know. This article aims to give you ‘food for thought’ about mental health apps from a slightly different angle than backend development. There is a big future in mental health apps, especially with [1 in 4 people diagnosed with mental illness in their lifetime] (http://www2.nami.org/factsheets/mentalillness_factsheet.pdf) and the cost and lack of access to local mental health professionals being significant barrier to mental health treatment for many people.#About meCate Lawrence is a writer and end user rather than a creator of technology. She has a background in mental health advocacy and is extremely interested in field of health apps. 